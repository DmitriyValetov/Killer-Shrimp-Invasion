{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "na_filling = \"imputer\"\n",
    "scaling = False\n",
    "overSample = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./train.csv\")\n",
    "test_df = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "columns = list(train_df.columns)\n",
    "\n",
    "features = [\n",
    "    'Salinity_today', \n",
    "    'Temperature_today', \n",
    "    'Substrate', \n",
    "    'Depth', \n",
    "    'Exposure', \n",
    "\n",
    "    'Temperature_today_exp', \n",
    "    'Depth_log', \n",
    "    'Exposure_log', \n",
    "    'Salin_div_depth',\n",
    "    'Temp_div_depth',\n",
    "    \n",
    "]\n",
    "\n",
    "categoricals = [\n",
    "    'Substrate',\n",
    "]\n",
    "\n",
    "numerical_features = [f for f in features if f not in categoricals]\n",
    "\n",
    "target = 'Presence'\n",
    "\n",
    "\n",
    "# init\n",
    "for f in features:\n",
    "    if f not in train_df:\n",
    "        train_df[f] = 0.0\n",
    "        test_df[f]  = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill Na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "\n",
    "if na_filling == \"imputer\":\n",
    "    imputer = IterativeImputer(max_iter = 10, random_state = RANDOM_STATE)\n",
    "    imputer.fit(train_df[features])\n",
    "    train_df[features] = pd.DataFrame(imputer.transform(train_df[features]), columns = features)\n",
    "    test_df[features] = pd.DataFrame(imputer.transform(test_df[features]), columns = features)\n",
    "\n",
    "else:\n",
    "    train_df[numerical_features] = train_df[numerical_features].fillna(train_df[numerical_features].median())\n",
    "    test_df[numerical_features] = test_df[numerical_features].fillna(test_df[numerical_features].median())\n",
    "\n",
    "    train_df[categoricals] = train_df[categoricals].fillna(train_df[categoricals].mode().iloc[0])\n",
    "    test_df[categoricals] = test_df[categoricals].fillna(test_df[categoricals].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Exposure_log'] = np.log(train_df['Exposure'])\n",
    "test_df['Exposure_log']  = np.log(test_df['Exposure'])\n",
    "\n",
    "train_df['Depth_log'] = np.log(np.abs(train_df['Depth']))\n",
    "test_df['Depth_log'] = np.log(np.abs(test_df['Depth']))\n",
    "\n",
    "train_df['Temperature_today_exp'] = np.exp(train_df['Temperature_today'])\n",
    "test_df['Temperature_today_exp'] = np.exp(test_df['Temperature_today'])\n",
    "\n",
    "train_df['Temp_div_depth'] = train_df['Temperature_today'] / train_df['Depth']\n",
    "test_df['Temp_div_depth'] = test_df['Temperature_today']   / test_df['Depth']\n",
    "\n",
    "train_df['Salin_div_depth'] = train_df['Salinity_today'] / train_df['Depth']\n",
    "test_df['Salin_div_depth'] = test_df['Salinity_today']   / test_df['Depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = set(features)\n",
    "for df in [train_df, test_df]:\n",
    "    for i in range(2, 7):\n",
    "        new_feature = f'Temperature_today^{i}'\n",
    "        df[new_feature] = df['Temperature_today'] ** i\n",
    "        features.add(new_feature)\n",
    "        \n",
    "features = list(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pointid</th>\n",
       "      <th>Salinity_today</th>\n",
       "      <th>Temperature_today</th>\n",
       "      <th>Substrate</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Exposure</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Temperature_today_exp</th>\n",
       "      <th>Depth_log</th>\n",
       "      <th>Exposure_log</th>\n",
       "      <th>Salin_div_depth</th>\n",
       "      <th>Temp_div_depth</th>\n",
       "      <th>Temperature_today^2</th>\n",
       "      <th>Temperature_today^3</th>\n",
       "      <th>Temperature_today^4</th>\n",
       "      <th>Temperature_today^5</th>\n",
       "      <th>Temperature_today^6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1557521</td>\n",
       "      <td>30.467175</td>\n",
       "      <td>6.472158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-124.810000</td>\n",
       "      <td>972065.250</td>\n",
       "      <td>0</td>\n",
       "      <td>646.878444</td>\n",
       "      <td>4.826793</td>\n",
       "      <td>13.787178</td>\n",
       "      <td>-0.244108</td>\n",
       "      <td>-0.051856</td>\n",
       "      <td>41.888834</td>\n",
       "      <td>271.111171</td>\n",
       "      <td>1754.674444</td>\n",
       "      <td>11356.530939</td>\n",
       "      <td>73501.267114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893106</td>\n",
       "      <td>5.571699</td>\n",
       "      <td>3.367225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.122131</td>\n",
       "      <td>19108.832</td>\n",
       "      <td>0</td>\n",
       "      <td>28.997952</td>\n",
       "      <td>1.811910</td>\n",
       "      <td>9.857906</td>\n",
       "      <td>-0.910091</td>\n",
       "      <td>-0.550009</td>\n",
       "      <td>11.338206</td>\n",
       "      <td>38.178291</td>\n",
       "      <td>128.554905</td>\n",
       "      <td>432.873316</td>\n",
       "      <td>1457.581937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1326854</td>\n",
       "      <td>6.657795</td>\n",
       "      <td>5.305255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-162.640000</td>\n",
       "      <td>772179.300</td>\n",
       "      <td>0</td>\n",
       "      <td>201.392431</td>\n",
       "      <td>5.091539</td>\n",
       "      <td>13.556972</td>\n",
       "      <td>-0.040936</td>\n",
       "      <td>-0.032620</td>\n",
       "      <td>28.145735</td>\n",
       "      <td>149.320312</td>\n",
       "      <td>792.182391</td>\n",
       "      <td>4202.729906</td>\n",
       "      <td>22296.555531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196477</td>\n",
       "      <td>2.744422</td>\n",
       "      <td>1.934046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-35.440000</td>\n",
       "      <td>407472.400</td>\n",
       "      <td>0</td>\n",
       "      <td>6.917444</td>\n",
       "      <td>3.567841</td>\n",
       "      <td>12.917728</td>\n",
       "      <td>-0.077439</td>\n",
       "      <td>-0.054572</td>\n",
       "      <td>3.740535</td>\n",
       "      <td>7.234369</td>\n",
       "      <td>13.991606</td>\n",
       "      <td>27.060415</td>\n",
       "      <td>52.336097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>168448</td>\n",
       "      <td>2.797321</td>\n",
       "      <td>2.039138</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-51.250000</td>\n",
       "      <td>408049.120</td>\n",
       "      <td>0</td>\n",
       "      <td>7.683983</td>\n",
       "      <td>3.936716</td>\n",
       "      <td>12.919143</td>\n",
       "      <td>-0.054582</td>\n",
       "      <td>-0.039788</td>\n",
       "      <td>4.158084</td>\n",
       "      <td>8.478907</td>\n",
       "      <td>17.289661</td>\n",
       "      <td>35.256004</td>\n",
       "      <td>71.891858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pointid  Salinity_today  Temperature_today  Substrate       Depth  \\\n",
       "0  1557521       30.467175           6.472158        1.0 -124.810000   \n",
       "1   893106        5.571699           3.367225        0.0   -6.122131   \n",
       "2  1326854        6.657795           5.305255        1.0 -162.640000   \n",
       "3   196477        2.744422           1.934046        0.0  -35.440000   \n",
       "4   168448        2.797321           2.039138        1.0  -51.250000   \n",
       "\n",
       "     Exposure  Presence  Temperature_today_exp  Depth_log  Exposure_log  \\\n",
       "0  972065.250         0             646.878444   4.826793     13.787178   \n",
       "1   19108.832         0              28.997952   1.811910      9.857906   \n",
       "2  772179.300         0             201.392431   5.091539     13.556972   \n",
       "3  407472.400         0               6.917444   3.567841     12.917728   \n",
       "4  408049.120         0               7.683983   3.936716     12.919143   \n",
       "\n",
       "   Salin_div_depth  Temp_div_depth  Temperature_today^2  Temperature_today^3  \\\n",
       "0        -0.244108       -0.051856            41.888834           271.111171   \n",
       "1        -0.910091       -0.550009            11.338206            38.178291   \n",
       "2        -0.040936       -0.032620            28.145735           149.320312   \n",
       "3        -0.077439       -0.054572             3.740535             7.234369   \n",
       "4        -0.054582       -0.039788             4.158084             8.478907   \n",
       "\n",
       "   Temperature_today^4  Temperature_today^5  Temperature_today^6  \n",
       "0          1754.674444         11356.530939         73501.267114  \n",
       "1           128.554905           432.873316          1457.581937  \n",
       "2           792.182391          4202.729906         22296.555531  \n",
       "3            13.991606            27.060415            52.336097  \n",
       "4            17.289661            35.256004            71.891858  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df = pd.concat([train_df[numerical_features], test_df[numerical_features]], ignore_index=True)\n",
    "scaler.fit(df[numerical_features])\n",
    "\n",
    "# x_test = test_df.copy()[features]\n",
    "# x_test[numerical_features] = scaler.transform(x_test[numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss, mean_squared_error, mean_absolute_error, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python37\\lib\\site-packages\\lightgbm\\basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.997799\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.999728\n",
      "[3]\tvalid_0's auc: 0.9997\n",
      "[4]\tvalid_0's auc: 0.99972\n",
      "[5]\tvalid_0's auc: 0.99972\n",
      "[6]\tvalid_0's auc: 0.99972\n",
      "[7]\tvalid_0's auc: 0.999736\n",
      "[8]\tvalid_0's auc: 0.999874\n",
      "[9]\tvalid_0's auc: 0.999874\n",
      "[10]\tvalid_0's auc: 0.999895\n",
      "[11]\tvalid_0's auc: 0.999895\n",
      "[12]\tvalid_0's auc: 0.999899\n",
      "[13]\tvalid_0's auc: 0.999899\n",
      "[14]\tvalid_0's auc: 0.99995\n",
      "[15]\tvalid_0's auc: 0.99995\n",
      "[16]\tvalid_0's auc: 0.999954\n",
      "[17]\tvalid_0's auc: 0.999954\n",
      "[18]\tvalid_0's auc: 0.999954\n",
      "[19]\tvalid_0's auc: 1\n",
      "[20]\tvalid_0's auc: 1\n",
      "[21]\tvalid_0's auc: 1\n",
      "[22]\tvalid_0's auc: 1\n",
      "[23]\tvalid_0's auc: 1\n",
      "[24]\tvalid_0's auc: 1\n",
      "[25]\tvalid_0's auc: 1\n",
      "[26]\tvalid_0's auc: 1\n",
      "[27]\tvalid_0's auc: 1\n",
      "[28]\tvalid_0's auc: 1\n",
      "[29]\tvalid_0's auc: 1\n",
      "[30]\tvalid_0's auc: 1\n",
      "[31]\tvalid_0's auc: 1\n",
      "[32]\tvalid_0's auc: 1\n",
      "[33]\tvalid_0's auc: 1\n",
      "[34]\tvalid_0's auc: 1\n",
      "[35]\tvalid_0's auc: 1\n",
      "[36]\tvalid_0's auc: 1\n",
      "[37]\tvalid_0's auc: 1\n",
      "[38]\tvalid_0's auc: 1\n",
      "[39]\tvalid_0's auc: 1\n",
      "[40]\tvalid_0's auc: 1\n",
      "[41]\tvalid_0's auc: 1\n",
      "[42]\tvalid_0's auc: 1\n",
      "[43]\tvalid_0's auc: 1\n",
      "[44]\tvalid_0's auc: 1\n",
      "[45]\tvalid_0's auc: 1\n",
      "[46]\tvalid_0's auc: 1\n",
      "[47]\tvalid_0's auc: 1\n",
      "[48]\tvalid_0's auc: 1\n",
      "[49]\tvalid_0's auc: 1\n",
      "[50]\tvalid_0's auc: 1\n",
      "[51]\tvalid_0's auc: 1\n",
      "[52]\tvalid_0's auc: 1\n",
      "[53]\tvalid_0's auc: 1\n",
      "[54]\tvalid_0's auc: 1\n",
      "[55]\tvalid_0's auc: 1\n",
      "[56]\tvalid_0's auc: 1\n",
      "[57]\tvalid_0's auc: 1\n",
      "[58]\tvalid_0's auc: 1\n",
      "[59]\tvalid_0's auc: 1\n",
      "[60]\tvalid_0's auc: 1\n",
      "[61]\tvalid_0's auc: 1\n",
      "[62]\tvalid_0's auc: 1\n",
      "[63]\tvalid_0's auc: 1\n",
      "[64]\tvalid_0's auc: 1\n",
      "[65]\tvalid_0's auc: 1\n",
      "[66]\tvalid_0's auc: 1\n",
      "[67]\tvalid_0's auc: 1\n",
      "[68]\tvalid_0's auc: 1\n",
      "[69]\tvalid_0's auc: 1\n",
      "[70]\tvalid_0's auc: 1\n",
      "[71]\tvalid_0's auc: 1\n",
      "[72]\tvalid_0's auc: 1\n",
      "[73]\tvalid_0's auc: 1\n",
      "[74]\tvalid_0's auc: 1\n",
      "[75]\tvalid_0's auc: 1\n",
      "[76]\tvalid_0's auc: 1\n",
      "[77]\tvalid_0's auc: 1\n",
      "[78]\tvalid_0's auc: 1\n",
      "[79]\tvalid_0's auc: 1\n",
      "[80]\tvalid_0's auc: 1\n",
      "[81]\tvalid_0's auc: 1\n",
      "[82]\tvalid_0's auc: 1\n",
      "[83]\tvalid_0's auc: 1\n",
      "[84]\tvalid_0's auc: 1\n",
      "[85]\tvalid_0's auc: 1\n",
      "[86]\tvalid_0's auc: 1\n",
      "[87]\tvalid_0's auc: 1\n",
      "[88]\tvalid_0's auc: 1\n",
      "[89]\tvalid_0's auc: 1\n",
      "[90]\tvalid_0's auc: 1\n",
      "[91]\tvalid_0's auc: 1\n",
      "[92]\tvalid_0's auc: 1\n",
      "[93]\tvalid_0's auc: 1\n",
      "[94]\tvalid_0's auc: 1\n",
      "[95]\tvalid_0's auc: 1\n",
      "[96]\tvalid_0's auc: 1\n",
      "[97]\tvalid_0's auc: 1\n",
      "[98]\tvalid_0's auc: 1\n",
      "[99]\tvalid_0's auc: 1\n",
      "[100]\tvalid_0's auc: 1\n",
      "[101]\tvalid_0's auc: 1\n",
      "[102]\tvalid_0's auc: 1\n",
      "[103]\tvalid_0's auc: 1\n",
      "[104]\tvalid_0's auc: 1\n",
      "[105]\tvalid_0's auc: 1\n",
      "[106]\tvalid_0's auc: 1\n",
      "[107]\tvalid_0's auc: 1\n",
      "[108]\tvalid_0's auc: 1\n",
      "[109]\tvalid_0's auc: 1\n",
      "[110]\tvalid_0's auc: 1\n",
      "[111]\tvalid_0's auc: 1\n",
      "[112]\tvalid_0's auc: 1\n",
      "[113]\tvalid_0's auc: 1\n",
      "[114]\tvalid_0's auc: 1\n",
      "[115]\tvalid_0's auc: 1\n",
      "[116]\tvalid_0's auc: 1\n",
      "[117]\tvalid_0's auc: 1\n",
      "[118]\tvalid_0's auc: 1\n",
      "[119]\tvalid_0's auc: 1\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 1\n",
      "Turn: 0 score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python37\\lib\\site-packages\\lightgbm\\basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.997728\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.999784\n",
      "[3]\tvalid_0's auc: 0.999688\n",
      "[4]\tvalid_0's auc: 0.999844\n",
      "[5]\tvalid_0's auc: 0.999844\n",
      "[6]\tvalid_0's auc: 1\n",
      "[7]\tvalid_0's auc: 1\n",
      "[8]\tvalid_0's auc: 1\n",
      "[9]\tvalid_0's auc: 1\n",
      "[10]\tvalid_0's auc: 1\n",
      "[11]\tvalid_0's auc: 1\n",
      "[12]\tvalid_0's auc: 1\n",
      "[13]\tvalid_0's auc: 1\n",
      "[14]\tvalid_0's auc: 1\n",
      "[15]\tvalid_0's auc: 1\n",
      "[16]\tvalid_0's auc: 1\n",
      "[17]\tvalid_0's auc: 1\n",
      "[18]\tvalid_0's auc: 1\n",
      "[19]\tvalid_0's auc: 1\n",
      "[20]\tvalid_0's auc: 1\n",
      "[21]\tvalid_0's auc: 1\n",
      "[22]\tvalid_0's auc: 1\n",
      "[23]\tvalid_0's auc: 1\n",
      "[24]\tvalid_0's auc: 1\n",
      "[25]\tvalid_0's auc: 1\n",
      "[26]\tvalid_0's auc: 1\n",
      "[27]\tvalid_0's auc: 1\n",
      "[28]\tvalid_0's auc: 1\n",
      "[29]\tvalid_0's auc: 1\n",
      "[30]\tvalid_0's auc: 1\n",
      "[31]\tvalid_0's auc: 1\n",
      "[32]\tvalid_0's auc: 1\n",
      "[33]\tvalid_0's auc: 1\n",
      "[34]\tvalid_0's auc: 1\n",
      "[35]\tvalid_0's auc: 1\n",
      "[36]\tvalid_0's auc: 1\n",
      "[37]\tvalid_0's auc: 1\n",
      "[38]\tvalid_0's auc: 1\n",
      "[39]\tvalid_0's auc: 1\n",
      "[40]\tvalid_0's auc: 1\n",
      "[41]\tvalid_0's auc: 1\n",
      "[42]\tvalid_0's auc: 1\n",
      "[43]\tvalid_0's auc: 1\n",
      "[44]\tvalid_0's auc: 1\n",
      "[45]\tvalid_0's auc: 1\n",
      "[46]\tvalid_0's auc: 1\n",
      "[47]\tvalid_0's auc: 1\n",
      "[48]\tvalid_0's auc: 1\n",
      "[49]\tvalid_0's auc: 1\n",
      "[50]\tvalid_0's auc: 1\n",
      "[51]\tvalid_0's auc: 1\n",
      "[52]\tvalid_0's auc: 1\n",
      "[53]\tvalid_0's auc: 1\n",
      "[54]\tvalid_0's auc: 1\n",
      "[55]\tvalid_0's auc: 1\n",
      "[56]\tvalid_0's auc: 1\n",
      "[57]\tvalid_0's auc: 1\n",
      "[58]\tvalid_0's auc: 1\n",
      "[59]\tvalid_0's auc: 1\n",
      "[60]\tvalid_0's auc: 1\n",
      "[61]\tvalid_0's auc: 1\n",
      "[62]\tvalid_0's auc: 1\n",
      "[63]\tvalid_0's auc: 1\n",
      "[64]\tvalid_0's auc: 1\n",
      "[65]\tvalid_0's auc: 1\n",
      "[66]\tvalid_0's auc: 1\n",
      "[67]\tvalid_0's auc: 1\n",
      "[68]\tvalid_0's auc: 1\n",
      "[69]\tvalid_0's auc: 1\n",
      "[70]\tvalid_0's auc: 1\n",
      "[71]\tvalid_0's auc: 1\n",
      "[72]\tvalid_0's auc: 1\n",
      "[73]\tvalid_0's auc: 1\n",
      "[74]\tvalid_0's auc: 1\n",
      "[75]\tvalid_0's auc: 1\n",
      "[76]\tvalid_0's auc: 1\n",
      "[77]\tvalid_0's auc: 1\n",
      "[78]\tvalid_0's auc: 1\n",
      "[79]\tvalid_0's auc: 1\n",
      "[80]\tvalid_0's auc: 1\n",
      "[81]\tvalid_0's auc: 1\n",
      "[82]\tvalid_0's auc: 1\n",
      "[83]\tvalid_0's auc: 1\n",
      "[84]\tvalid_0's auc: 1\n",
      "[85]\tvalid_0's auc: 1\n",
      "[86]\tvalid_0's auc: 1\n",
      "[87]\tvalid_0's auc: 1\n",
      "[88]\tvalid_0's auc: 1\n",
      "[89]\tvalid_0's auc: 1\n",
      "[90]\tvalid_0's auc: 1\n",
      "[91]\tvalid_0's auc: 1\n",
      "[92]\tvalid_0's auc: 1\n",
      "[93]\tvalid_0's auc: 1\n",
      "[94]\tvalid_0's auc: 1\n",
      "[95]\tvalid_0's auc: 1\n",
      "[96]\tvalid_0's auc: 1\n",
      "[97]\tvalid_0's auc: 1\n",
      "[98]\tvalid_0's auc: 1\n",
      "[99]\tvalid_0's auc: 1\n",
      "[100]\tvalid_0's auc: 1\n",
      "[101]\tvalid_0's auc: 1\n",
      "[102]\tvalid_0's auc: 1\n",
      "[103]\tvalid_0's auc: 1\n",
      "[104]\tvalid_0's auc: 1\n",
      "[105]\tvalid_0's auc: 1\n",
      "[106]\tvalid_0's auc: 1\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 1\n",
      "Turn: 1 score: 0.9999999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python37\\lib\\site-packages\\lightgbm\\basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.998012\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.999894\n",
      "[3]\tvalid_0's auc: 0.999846\n",
      "[4]\tvalid_0's auc: 0.999846\n",
      "[5]\tvalid_0's auc: 0.999846\n",
      "[6]\tvalid_0's auc: 0.999846\n",
      "[7]\tvalid_0's auc: 0.999846\n",
      "[8]\tvalid_0's auc: 0.999846\n",
      "[9]\tvalid_0's auc: 0.999846\n",
      "[10]\tvalid_0's auc: 0.999846\n",
      "[11]\tvalid_0's auc: 0.999849\n",
      "[12]\tvalid_0's auc: 0.999874\n",
      "[13]\tvalid_0's auc: 0.999874\n",
      "[14]\tvalid_0's auc: 0.999882\n",
      "[15]\tvalid_0's auc: 0.999882\n",
      "[16]\tvalid_0's auc: 0.999882\n",
      "[17]\tvalid_0's auc: 0.999936\n",
      "[18]\tvalid_0's auc: 0.999936\n",
      "[19]\tvalid_0's auc: 0.999939\n",
      "[20]\tvalid_0's auc: 0.999931\n",
      "[21]\tvalid_0's auc: 0.999903\n",
      "[22]\tvalid_0's auc: 0.999903\n",
      "[23]\tvalid_0's auc: 0.999903\n",
      "[24]\tvalid_0's auc: 0.999903\n",
      "[25]\tvalid_0's auc: 0.999917\n",
      "[26]\tvalid_0's auc: 1\n",
      "[27]\tvalid_0's auc: 1\n",
      "[28]\tvalid_0's auc: 1\n",
      "[29]\tvalid_0's auc: 1\n",
      "[30]\tvalid_0's auc: 1\n",
      "[31]\tvalid_0's auc: 1\n",
      "[32]\tvalid_0's auc: 1\n",
      "[33]\tvalid_0's auc: 1\n",
      "[34]\tvalid_0's auc: 1\n",
      "[35]\tvalid_0's auc: 1\n",
      "[36]\tvalid_0's auc: 1\n",
      "[37]\tvalid_0's auc: 1\n",
      "[38]\tvalid_0's auc: 1\n",
      "[39]\tvalid_0's auc: 1\n",
      "[40]\tvalid_0's auc: 1\n",
      "[41]\tvalid_0's auc: 1\n",
      "[42]\tvalid_0's auc: 1\n",
      "[43]\tvalid_0's auc: 1\n",
      "[44]\tvalid_0's auc: 1\n",
      "[45]\tvalid_0's auc: 1\n",
      "[46]\tvalid_0's auc: 1\n",
      "[47]\tvalid_0's auc: 1\n",
      "[48]\tvalid_0's auc: 1\n",
      "[49]\tvalid_0's auc: 1\n",
      "[50]\tvalid_0's auc: 1\n",
      "[51]\tvalid_0's auc: 1\n",
      "[52]\tvalid_0's auc: 1\n",
      "[53]\tvalid_0's auc: 1\n",
      "[54]\tvalid_0's auc: 1\n",
      "[55]\tvalid_0's auc: 1\n",
      "[56]\tvalid_0's auc: 1\n",
      "[57]\tvalid_0's auc: 1\n",
      "[58]\tvalid_0's auc: 1\n",
      "[59]\tvalid_0's auc: 1\n",
      "[60]\tvalid_0's auc: 1\n",
      "[61]\tvalid_0's auc: 1\n",
      "[62]\tvalid_0's auc: 1\n",
      "[63]\tvalid_0's auc: 1\n",
      "[64]\tvalid_0's auc: 1\n",
      "[65]\tvalid_0's auc: 1\n",
      "[66]\tvalid_0's auc: 1\n",
      "[67]\tvalid_0's auc: 1\n",
      "[68]\tvalid_0's auc: 1\n",
      "[69]\tvalid_0's auc: 1\n",
      "[70]\tvalid_0's auc: 1\n",
      "[71]\tvalid_0's auc: 1\n",
      "[72]\tvalid_0's auc: 1\n",
      "[73]\tvalid_0's auc: 1\n",
      "[74]\tvalid_0's auc: 1\n",
      "[75]\tvalid_0's auc: 1\n",
      "[76]\tvalid_0's auc: 1\n",
      "[77]\tvalid_0's auc: 1\n",
      "[78]\tvalid_0's auc: 1\n",
      "[79]\tvalid_0's auc: 1\n",
      "[80]\tvalid_0's auc: 1\n",
      "[81]\tvalid_0's auc: 1\n",
      "[82]\tvalid_0's auc: 1\n",
      "[83]\tvalid_0's auc: 1\n",
      "[84]\tvalid_0's auc: 1\n",
      "[85]\tvalid_0's auc: 1\n",
      "[86]\tvalid_0's auc: 1\n",
      "[87]\tvalid_0's auc: 1\n",
      "[88]\tvalid_0's auc: 1\n",
      "[89]\tvalid_0's auc: 1\n",
      "[90]\tvalid_0's auc: 1\n",
      "[91]\tvalid_0's auc: 1\n",
      "[92]\tvalid_0's auc: 1\n",
      "[93]\tvalid_0's auc: 1\n",
      "[94]\tvalid_0's auc: 1\n",
      "[95]\tvalid_0's auc: 1\n",
      "[96]\tvalid_0's auc: 1\n",
      "[97]\tvalid_0's auc: 1\n",
      "[98]\tvalid_0's auc: 1\n",
      "[99]\tvalid_0's auc: 1\n",
      "[100]\tvalid_0's auc: 1\n",
      "[101]\tvalid_0's auc: 1\n",
      "[102]\tvalid_0's auc: 1\n",
      "[103]\tvalid_0's auc: 1\n",
      "[104]\tvalid_0's auc: 1\n",
      "[105]\tvalid_0's auc: 1\n",
      "[106]\tvalid_0's auc: 1\n",
      "[107]\tvalid_0's auc: 1\n",
      "[108]\tvalid_0's auc: 1\n",
      "[109]\tvalid_0's auc: 1\n",
      "[110]\tvalid_0's auc: 1\n",
      "[111]\tvalid_0's auc: 1\n",
      "[112]\tvalid_0's auc: 1\n",
      "[113]\tvalid_0's auc: 1\n",
      "[114]\tvalid_0's auc: 1\n",
      "[115]\tvalid_0's auc: 1\n",
      "[116]\tvalid_0's auc: 1\n",
      "[117]\tvalid_0's auc: 1\n",
      "[118]\tvalid_0's auc: 1\n",
      "[119]\tvalid_0's auc: 1\n",
      "[120]\tvalid_0's auc: 1\n",
      "[121]\tvalid_0's auc: 1\n",
      "[122]\tvalid_0's auc: 1\n",
      "[123]\tvalid_0's auc: 1\n",
      "[124]\tvalid_0's auc: 1\n",
      "[125]\tvalid_0's auc: 1\n",
      "[126]\tvalid_0's auc: 1\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 1\n",
      "Turn: 2 score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python37\\lib\\site-packages\\lightgbm\\basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.998545\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.999788\n",
      "[3]\tvalid_0's auc: 0.999692\n",
      "[4]\tvalid_0's auc: 0.999846\n",
      "[5]\tvalid_0's auc: 0.999846\n",
      "[6]\tvalid_0's auc: 0.999846\n",
      "[7]\tvalid_0's auc: 0.999846\n",
      "[8]\tvalid_0's auc: 0.999853\n",
      "[9]\tvalid_0's auc: 0.999853\n",
      "[10]\tvalid_0's auc: 0.999853\n",
      "[11]\tvalid_0's auc: 0.999853\n",
      "[12]\tvalid_0's auc: 0.999849\n",
      "[13]\tvalid_0's auc: 0.999849\n",
      "[14]\tvalid_0's auc: 0.999853\n",
      "[15]\tvalid_0's auc: 0.999853\n",
      "[16]\tvalid_0's auc: 0.999931\n",
      "[17]\tvalid_0's auc: 0.999931\n",
      "[18]\tvalid_0's auc: 0.999931\n",
      "[19]\tvalid_0's auc: 0.999937\n",
      "[20]\tvalid_0's auc: 0.99992\n",
      "[21]\tvalid_0's auc: 0.9999\n",
      "[22]\tvalid_0's auc: 0.999896\n",
      "[23]\tvalid_0's auc: 0.999917\n",
      "[24]\tvalid_0's auc: 0.999917\n",
      "[25]\tvalid_0's auc: 0.999921\n",
      "[26]\tvalid_0's auc: 0.999921\n",
      "[27]\tvalid_0's auc: 0.999921\n",
      "[28]\tvalid_0's auc: 0.999921\n",
      "[29]\tvalid_0's auc: 0.999921\n",
      "[30]\tvalid_0's auc: 0.999921\n",
      "[31]\tvalid_0's auc: 0.999921\n",
      "[32]\tvalid_0's auc: 0.999921\n",
      "[33]\tvalid_0's auc: 0.999924\n",
      "[34]\tvalid_0's auc: 0.999921\n",
      "[35]\tvalid_0's auc: 0.999921\n",
      "[36]\tvalid_0's auc: 0.999921\n",
      "[37]\tvalid_0's auc: 0.999921\n",
      "[38]\tvalid_0's auc: 0.999921\n",
      "[39]\tvalid_0's auc: 0.999921\n",
      "[40]\tvalid_0's auc: 1\n",
      "[41]\tvalid_0's auc: 1\n",
      "[42]\tvalid_0's auc: 1\n",
      "[43]\tvalid_0's auc: 1\n",
      "[44]\tvalid_0's auc: 1\n",
      "[45]\tvalid_0's auc: 1\n",
      "[46]\tvalid_0's auc: 1\n",
      "[47]\tvalid_0's auc: 1\n",
      "[48]\tvalid_0's auc: 1\n",
      "[49]\tvalid_0's auc: 1\n",
      "[50]\tvalid_0's auc: 1\n",
      "[51]\tvalid_0's auc: 1\n",
      "[52]\tvalid_0's auc: 1\n",
      "[53]\tvalid_0's auc: 1\n",
      "[54]\tvalid_0's auc: 1\n",
      "[55]\tvalid_0's auc: 1\n",
      "[56]\tvalid_0's auc: 1\n",
      "[57]\tvalid_0's auc: 1\n",
      "[58]\tvalid_0's auc: 1\n",
      "[59]\tvalid_0's auc: 1\n",
      "[60]\tvalid_0's auc: 1\n",
      "[61]\tvalid_0's auc: 1\n",
      "[62]\tvalid_0's auc: 1\n",
      "[63]\tvalid_0's auc: 1\n",
      "[64]\tvalid_0's auc: 1\n",
      "[65]\tvalid_0's auc: 1\n",
      "[66]\tvalid_0's auc: 1\n",
      "[67]\tvalid_0's auc: 1\n",
      "[68]\tvalid_0's auc: 1\n",
      "[69]\tvalid_0's auc: 1\n",
      "[70]\tvalid_0's auc: 1\n",
      "[71]\tvalid_0's auc: 1\n",
      "[72]\tvalid_0's auc: 1\n",
      "[73]\tvalid_0's auc: 1\n",
      "[74]\tvalid_0's auc: 1\n",
      "[75]\tvalid_0's auc: 1\n",
      "[76]\tvalid_0's auc: 1\n",
      "[77]\tvalid_0's auc: 1\n",
      "[78]\tvalid_0's auc: 1\n",
      "[79]\tvalid_0's auc: 1\n",
      "[80]\tvalid_0's auc: 1\n",
      "[81]\tvalid_0's auc: 1\n",
      "[82]\tvalid_0's auc: 1\n",
      "[83]\tvalid_0's auc: 1\n",
      "[84]\tvalid_0's auc: 1\n",
      "[85]\tvalid_0's auc: 1\n",
      "[86]\tvalid_0's auc: 1\n",
      "[87]\tvalid_0's auc: 1\n",
      "[88]\tvalid_0's auc: 1\n",
      "[89]\tvalid_0's auc: 1\n",
      "[90]\tvalid_0's auc: 1\n",
      "[91]\tvalid_0's auc: 1\n",
      "[92]\tvalid_0's auc: 1\n",
      "[93]\tvalid_0's auc: 1\n",
      "[94]\tvalid_0's auc: 1\n",
      "[95]\tvalid_0's auc: 1\n",
      "[96]\tvalid_0's auc: 1\n",
      "[97]\tvalid_0's auc: 1\n",
      "[98]\tvalid_0's auc: 1\n",
      "[99]\tvalid_0's auc: 1\n",
      "[100]\tvalid_0's auc: 1\n",
      "[101]\tvalid_0's auc: 1\n",
      "[102]\tvalid_0's auc: 1\n",
      "[103]\tvalid_0's auc: 1\n",
      "[104]\tvalid_0's auc: 1\n",
      "[105]\tvalid_0's auc: 1\n",
      "[106]\tvalid_0's auc: 1\n",
      "[107]\tvalid_0's auc: 1\n",
      "[108]\tvalid_0's auc: 1\n",
      "[109]\tvalid_0's auc: 1\n",
      "[110]\tvalid_0's auc: 1\n",
      "[111]\tvalid_0's auc: 1\n",
      "[112]\tvalid_0's auc: 1\n",
      "[113]\tvalid_0's auc: 1\n",
      "[114]\tvalid_0's auc: 1\n",
      "[115]\tvalid_0's auc: 1\n",
      "[116]\tvalid_0's auc: 1\n",
      "[117]\tvalid_0's auc: 1\n",
      "[118]\tvalid_0's auc: 1\n",
      "[119]\tvalid_0's auc: 1\n",
      "[120]\tvalid_0's auc: 1\n",
      "[121]\tvalid_0's auc: 1\n",
      "[122]\tvalid_0's auc: 1\n",
      "[123]\tvalid_0's auc: 1\n",
      "[124]\tvalid_0's auc: 1\n",
      "[125]\tvalid_0's auc: 1\n",
      "[126]\tvalid_0's auc: 1\n",
      "[127]\tvalid_0's auc: 1\n",
      "[128]\tvalid_0's auc: 1\n",
      "[129]\tvalid_0's auc: 1\n",
      "[130]\tvalid_0's auc: 1\n",
      "[131]\tvalid_0's auc: 1\n",
      "[132]\tvalid_0's auc: 1\n",
      "[133]\tvalid_0's auc: 1\n",
      "[134]\tvalid_0's auc: 1\n",
      "[135]\tvalid_0's auc: 1\n",
      "[136]\tvalid_0's auc: 1\n",
      "[137]\tvalid_0's auc: 1\n",
      "[138]\tvalid_0's auc: 1\n",
      "[139]\tvalid_0's auc: 1\n",
      "[140]\tvalid_0's auc: 1\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's auc: 1\n",
      "Turn: 3 score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python37\\lib\\site-packages\\lightgbm\\basic.py:1291: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.998524\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.999841\n",
      "[3]\tvalid_0's auc: 0.999979\n",
      "[4]\tvalid_0's auc: 1\n",
      "[5]\tvalid_0's auc: 1\n",
      "[6]\tvalid_0's auc: 1\n",
      "[7]\tvalid_0's auc: 1\n",
      "[8]\tvalid_0's auc: 1\n",
      "[9]\tvalid_0's auc: 1\n",
      "[10]\tvalid_0's auc: 1\n",
      "[11]\tvalid_0's auc: 1\n",
      "[12]\tvalid_0's auc: 1\n",
      "[13]\tvalid_0's auc: 1\n",
      "[14]\tvalid_0's auc: 1\n",
      "[15]\tvalid_0's auc: 1\n",
      "[16]\tvalid_0's auc: 1\n",
      "[17]\tvalid_0's auc: 1\n",
      "[18]\tvalid_0's auc: 1\n",
      "[19]\tvalid_0's auc: 1\n",
      "[20]\tvalid_0's auc: 1\n",
      "[21]\tvalid_0's auc: 1\n",
      "[22]\tvalid_0's auc: 1\n",
      "[23]\tvalid_0's auc: 1\n",
      "[24]\tvalid_0's auc: 1\n",
      "[25]\tvalid_0's auc: 1\n",
      "[26]\tvalid_0's auc: 1\n",
      "[27]\tvalid_0's auc: 1\n",
      "[28]\tvalid_0's auc: 1\n",
      "[29]\tvalid_0's auc: 1\n",
      "[30]\tvalid_0's auc: 1\n",
      "[31]\tvalid_0's auc: 1\n",
      "[32]\tvalid_0's auc: 1\n",
      "[33]\tvalid_0's auc: 1\n",
      "[34]\tvalid_0's auc: 1\n",
      "[35]\tvalid_0's auc: 1\n",
      "[36]\tvalid_0's auc: 1\n",
      "[37]\tvalid_0's auc: 1\n",
      "[38]\tvalid_0's auc: 1\n",
      "[39]\tvalid_0's auc: 1\n",
      "[40]\tvalid_0's auc: 1\n",
      "[41]\tvalid_0's auc: 1\n",
      "[42]\tvalid_0's auc: 1\n",
      "[43]\tvalid_0's auc: 1\n",
      "[44]\tvalid_0's auc: 1\n",
      "[45]\tvalid_0's auc: 1\n",
      "[46]\tvalid_0's auc: 1\n",
      "[47]\tvalid_0's auc: 1\n",
      "[48]\tvalid_0's auc: 1\n",
      "[49]\tvalid_0's auc: 1\n",
      "[50]\tvalid_0's auc: 1\n",
      "[51]\tvalid_0's auc: 1\n",
      "[52]\tvalid_0's auc: 1\n",
      "[53]\tvalid_0's auc: 1\n",
      "[54]\tvalid_0's auc: 1\n",
      "[55]\tvalid_0's auc: 1\n",
      "[56]\tvalid_0's auc: 1\n",
      "[57]\tvalid_0's auc: 1\n",
      "[58]\tvalid_0's auc: 1\n",
      "[59]\tvalid_0's auc: 1\n",
      "[60]\tvalid_0's auc: 1\n",
      "[61]\tvalid_0's auc: 1\n",
      "[62]\tvalid_0's auc: 1\n",
      "[63]\tvalid_0's auc: 1\n",
      "[64]\tvalid_0's auc: 1\n",
      "[65]\tvalid_0's auc: 1\n",
      "[66]\tvalid_0's auc: 1\n",
      "[67]\tvalid_0's auc: 1\n",
      "[68]\tvalid_0's auc: 1\n",
      "[69]\tvalid_0's auc: 1\n",
      "[70]\tvalid_0's auc: 1\n",
      "[71]\tvalid_0's auc: 1\n",
      "[72]\tvalid_0's auc: 1\n",
      "[73]\tvalid_0's auc: 1\n",
      "[74]\tvalid_0's auc: 1\n",
      "[75]\tvalid_0's auc: 1\n",
      "[76]\tvalid_0's auc: 1\n",
      "[77]\tvalid_0's auc: 1\n",
      "[78]\tvalid_0's auc: 1\n",
      "[79]\tvalid_0's auc: 1\n",
      "[80]\tvalid_0's auc: 1\n",
      "[81]\tvalid_0's auc: 1\n",
      "[82]\tvalid_0's auc: 1\n",
      "[83]\tvalid_0's auc: 1\n",
      "[84]\tvalid_0's auc: 1\n",
      "[85]\tvalid_0's auc: 1\n",
      "[86]\tvalid_0's auc: 1\n",
      "[87]\tvalid_0's auc: 1\n",
      "[88]\tvalid_0's auc: 1\n",
      "[89]\tvalid_0's auc: 1\n",
      "[90]\tvalid_0's auc: 1\n",
      "[91]\tvalid_0's auc: 1\n",
      "[92]\tvalid_0's auc: 1\n",
      "[93]\tvalid_0's auc: 1\n",
      "[94]\tvalid_0's auc: 1\n",
      "[95]\tvalid_0's auc: 1\n",
      "[96]\tvalid_0's auc: 1\n",
      "[97]\tvalid_0's auc: 1\n",
      "[98]\tvalid_0's auc: 1\n",
      "[99]\tvalid_0's auc: 1\n",
      "[100]\tvalid_0's auc: 1\n",
      "[101]\tvalid_0's auc: 1\n",
      "[102]\tvalid_0's auc: 1\n",
      "[103]\tvalid_0's auc: 1\n",
      "[104]\tvalid_0's auc: 1\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 1\n",
      "Turn: 4 score: 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'application': 'binary',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': 'true',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'learning_rate': 0.05,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "models = []\n",
    "\n",
    "for turn_i in range(5):\n",
    "    ros = RandomOverSampler()\n",
    "    _, _ = ros.fit_resample(train_df[features], train_df.Presence)\n",
    "    train_idx = ros.sample_indices_\n",
    "        \n",
    "    resampled_df = shuffle(train_df.loc[train_idx])\n",
    "    x_train = resampled_df[features][10000:]\n",
    "    x_val   = resampled_df[features][:10000]\n",
    "    y_train = resampled_df[target][10000:]\n",
    "    y_val   = resampled_df[target][:10000]\n",
    "    \n",
    "    train_data = lightgbm.Dataset(x_train, feature_name=features, label=y_train, categorical_feature=categoricals)\n",
    "    val_data = lightgbm.Dataset(x_val, feature_name=features, label=y_val, categorical_feature=categoricals)\n",
    "    \n",
    "    model = lightgbm.train(parameters,\n",
    "                   train_data,\n",
    "                   valid_sets=val_data,\n",
    "                   num_boost_round=5000,\n",
    "                   early_stopping_rounds=100)\n",
    "\n",
    "    \n",
    "    val_pred = model.predict(x_val)\n",
    "    score = roc_auc_score(y_val, val_pred)\n",
    "    models.append([score, turn_i])\n",
    "    model.save_model(f\"model_{turn_i}.lgbm\")\n",
    "    print('Turn: {} score: {}'.format(turn_i, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict proba by best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.sort(key=lambda x: x[0])\n",
    "best_model_i = models[-1][1]\n",
    "best_model = lightgbm.Booster(model_file=f\"model_{best_model_i}.lgbm\")\n",
    "\n",
    "y_probas = best_model.predict(test_df[features])\n",
    "\n",
    "result = pd.read_csv(\"temperature_submission.csv\")\n",
    "result.Presence = y_probas.round(3)\n",
    "result.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found killers: 68553.26599961848\n"
     ]
    }
   ],
   "source": [
    "result = pd.read_csv(\"temperature_submission.csv\")\n",
    "result.Presence = 0\n",
    "\n",
    "for i in range(len(models)):\n",
    "    model = lightgbm.Booster(model_file=f\"model_{i}.lgbm\")\n",
    "    y_probas = model.predict(test_df[features])\n",
    "    result.Presence += y_probas\n",
    "\n",
    "result.Presence = (result.Presence / len(models)).round(3)\n",
    "print(f\"Found killers: {sum(result.Presence)}\")\n",
    "result.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c killer-shrimp-invasion -f submission.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://catboost.ai/docs/concepts/python-reference_pool.html\n",
    "\n",
    "https://catboost.ai/docs/concepts/python-reference_parameters-list.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
